{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导出带注释的po文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择角色\n",
    "char = \"wilson\"\n",
    "char = char.upper()\n",
    "# 环境\n",
    "dst_base = \"e:/dst/scripts\"\n",
    "speech_base = f\"{dst_base}/root/\"\n",
    "comment_file = \"E:/dst/other/comment202405_other.json\"\n",
    "# 另一个角色\n",
    "char_candidates = [\"willow\", \"wendy\"]\n",
    "char_candidate = char_candidates[0]\n",
    "if char == char_candidate:\n",
    "    char_candidate = char_candidates[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取speech_char.lua\n",
    "import os\n",
    "import json\n",
    "from lupa.lua51 import LuaRuntime\n",
    "import lupa.lua51 as lupa\n",
    "\n",
    "\n",
    "def read_lua_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads a Lua file and returns the value returned by the Lua file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the Lua file.\n",
    "\n",
    "    Returns:\n",
    "        dict: The value returned by the Lua file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a Lua runtime\n",
    "        lua = LuaRuntime(unpack_returned_tuples=True)\n",
    "\n",
    "        # Load the Lua file\n",
    "        with open(file_path, \"r\") as file:\n",
    "            lua_code = file.read()\n",
    "        lua_chunk = lua.execute(lua_code)\n",
    "\n",
    "        # Call the Lua chunk to get the returned value\n",
    "        return_value = lua_chunk\n",
    "        return return_value\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Lua file: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def lua_table_to_python(table, parent_key=None):\n",
    "    \"\"\"\n",
    "    Recursively traverses a Lua table and builds a tree-like Python dictionary.\n",
    "\n",
    "    Args:\n",
    "        table (lupa.lua.LuaTable): The Lua table to be traversed.\n",
    "        parent_key (str, optional): The key of the parent table, if any.\n",
    "\n",
    "    Returns:\n",
    "        dict: The tree-like Python dictionary.\n",
    "    \"\"\"\n",
    "    python_dict = {}\n",
    "\n",
    "    for key, value in table.items():\n",
    "        if lupa.lua_type(value) == \"table\":\n",
    "            # Recursive case: the value is another Lua table\n",
    "            python_dict[str(key)] = lua_table_to_python(value, str(key))\n",
    "        else:\n",
    "            # Base case: the value is a leaf node\n",
    "            python_dict[str(key)] = str(value)\n",
    "\n",
    "    return python_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#首先读取speech_char.lua\n",
    "speech_char=read_lua_file(f\"{speech_base}/speech_{char}.lua\")\n",
    "speech_char=lua_table_to_python(speech_char)\n",
    "#其次读取对照speech_candidate.lua\n",
    "speech_candidate=read_lua_file(f\"{speech_base}/speech_{char_candidate}.lua\")\n",
    "speech_candidate=lua_table_to_python(speech_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 展平字典\n",
    "def flatten_dict(d, parent_key=\"\", sep=\".\"):\n",
    "    \"\"\"\n",
    "    Flattens a nested dictionary into a flat dictionary with concatenated keys.\n",
    "\n",
    "    Args:\n",
    "        d (dict): The input nested dictionary to be flattened.\n",
    "        parent_key (str): The current concatenated key (if any).\n",
    "        sep (str): The separator character used to concatenate the keys.\n",
    "\n",
    "    Returns:\n",
    "        dict: The flattened dictionary with concatenated keys.\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#转换为平坦字典\n",
    "string_char = flatten_dict(speech_char)\n",
    "string_candidate = flatten_dict(speech_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取交集\n",
    "def dict_intersect(dict1, dict2):\n",
    "    \"\"\"\n",
    "    Returns the intersection of two dictionaries, excluding any key-value pairs where the value contains the string \"only_used\".\n",
    "\n",
    "    Args:\n",
    "        dict1 (dict): The first dictionary.\n",
    "        dict2 (dict): The second dictionary.\n",
    "\n",
    "    Returns:\n",
    "        dict: The intersection of the two dictionaries, excluding any key-value pairs where the value contains \"only_used\".\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for key in set(dict1.keys()) & set(dict2.keys()):\n",
    "        if \"only_used\" not in str(dict1[key]) and \"only_used\" not in str(dict2[key]):\n",
    "            result[key] = dict1[key]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 求出交集\n",
    "intersect_char = dict_intersect(string_char, string_candidate)\n",
    "intersect_key = set(intersect_char.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "__cached_path = \"\"\n",
    "__cached_json = None\n",
    "\n",
    "\n",
    "def loadjson(path):\n",
    "    global __cached_path, __cached_json\n",
    "    if path == __cached_path:\n",
    "        return __cached_json\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        __cached_json = json.load(f)\n",
    "        __cached_path = path\n",
    "        return __cached_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载make po文件\n",
    "from make_po import PO\n",
    "import polib\n",
    "\n",
    "# 打开标准po文件\n",
    "chinese_po = PO(f\"{dst_base}/languages/chinese_s.po\")\n",
    "# 打开注释文件\n",
    "comment_dict = loadjson(comment_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查找注释\n",
    "def find_comment(id):\n",
    "    if id in comment_dict:\n",
    "        return comment_dict[id]\n",
    "    if id.startswith(\"DESCRIBE\"):\n",
    "        item = id.split(\".\")[1]\n",
    "        item_key = f\"STRINGS.NAMES.{item}\"\n",
    "        item_generic_key = f\"STRINGS.NAMES.{item}.GENERIC\"\n",
    "        ret = []\n",
    "        if item_key in chinese_po.po_dict:\n",
    "            ret.append(f\"物品名:{chinese_po.po_dict[item_key]}\")\n",
    "        elif item_generic_key in chinese_po.po_dict:\n",
    "            print(\"Found a generic item\", item)\n",
    "            ret.append(f\"物品名:{chinese_po.po_dict[item_generic_key]}\")\n",
    "        item_recipe_key = f\"STRINGS.RECIPE_DESC.{item}\"\n",
    "        if item_recipe_key in chinese_po.po_dict:\n",
    "            ret.append(f\"配方描述:{chinese_po.po_dict[item_recipe_key]}\")\n",
    "        return \" \".join(ret)\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取全部key\n",
    "all_keys = intersect_key\n",
    "prefix = \"STRINGS.CHARACTERS.\"\n",
    "char_alias = char if char != \"WILSON\" else \"GENERIC\"\n",
    "prefix_char = f\"{prefix}{char_alias}.\"\n",
    "prefix_pure = f\"{prefix}{char}.\"\n",
    "extract_po = PO()\n",
    "extract_po.po = extract_po.po or polib.POFile()\n",
    "for i in chinese_po.po:\n",
    "    id = i.msgctxt\n",
    "    en = i.msgid\n",
    "    zh = i.msgstr\n",
    "    cmt = None\n",
    "    pure_id = id\n",
    "    if pure_id.startswith(prefix_char):\n",
    "        pure_id = pure_id[len(prefix_char) :]\n",
    "        if pure_id in all_keys:\n",
    "            cmt = find_comment(pure_id)\n",
    "            pure_id = prefix_pure + pure_id\n",
    "            extract_po.add(\n",
    "                polib.POEntry(msgctxt=pure_id, msgid=en, msgstr=zh, comment=cmt)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_po.po_path=f\"{char}.po\"\n",
    "extract_po.save(f\"{char}.po\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
